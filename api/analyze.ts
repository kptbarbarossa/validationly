import { GoogleGenAI } from "@google/genai";
import OpenAI from 'openai';
import Groq from 'groq-sdk';

// AI-Only Analysis System - No external data fetching
// Uses only the AI model's own knowledge base and reasoning

interface AnalysisInput {
  idea: string;
  audience?: string;
  goal?: string;
  constraints?: string;
}

interface Assumption {
  text: string;
  confidence: number;
}

interface DemandSignal {
  signal: string;
  evidence: string;
  confidence: number;
}

interface Risk {
  type: 'product' | 'market' | 'execution' | 'legal';
  likelihood: number;
  impact: number;
  note: string;
}

interface ValidationPlan {
  name: string;
  cost: 'low' | 'medium' | 'high';
  metric: string;
  success_criteria: string;
}

interface PricingHypothesis {
  plan_free: string;
  plan_pro: string;
  price_range: string;
}

interface GTM {
  ICP: string[];
  channels: string[];
  positioning: string;
  pricing_hypothesis: PricingHypothesis;
}

interface ScoreBreakdown {
  novelty: number;
  demand_plausibility: number;
  monetization_clarity: number;
  feasibility: number;
  gtm_fit: number;
}

interface AnalysisResult {
  idea_summary: string;
  assumptions: Assumption[];
  target_audience: string[];
  jobs_to_be_done: string[];
  value_hypotheses: string[];
  demand_signals: DemandSignal[];
  competitive_landscape: {
    substitutes: string[];
    adjacent_tools: string[];
    moat_likelihood: number;
  };
  risks: Risk[];
  validation_plan: ValidationPlan[];
  gtm: GTM;
  score_breakdown: ScoreBreakdown;
  final_score: number;
  uncertainty_note: string;
}

// AI Model Selection
function getAI() {
  const model = process.env.PREFERRED_AI_MODEL || 'gemini';
  
  switch (model) {
    case 'openai':
      if (!process.env.OPENAI_API_KEY) {
        throw new Error('OpenAI API key not configured');
      }
      return {
        type: 'openai',
        instance: new OpenAI({ apiKey: process.env.OPENAI_API_KEY })
      };
    
    case 'groq':
      if (!process.env.GROQ_API_KEY) {
        throw new Error('Groq API key not configured');
      }
      return {
        type: 'groq',
        instance: new Groq({ apiKey: process.env.GROQ_API_KEY })
      };
    
    case 'gemini':
    default:
      if (!process.env.GOOGLE_API_KEY) {
        throw new Error('Google API key not configured');
      }
      return {
        type: 'gemini',
        instance: new GoogleGenAI({ apiKey: process.env.GOOGLE_API_KEY })
      };
  }
}

// AI Analysis Prompt
const ANALYSIS_PROMPT = `# Cursor Prompt â€” AIâ€‘Only Analysis (Validationly + Vercel)

**Role:** Senior Product Strategist & LLM Architect. **Sadece yapay zekanÄ±n kendi bilgisini** kullanarak analiz yap. **Kesinlikle dÄ±ÅŸ veri Ã§ekme** (web scrape, API Ã§aÄŸrÄ±sÄ±, arama yok). Kod Ã¼retme aÅŸamasÄ±na geÃ§meden Ã¶nce **tek bir analiz Ã§Ä±ktÄ±sÄ±** Ã¼ret.

---

## 0) Kapsam ve KÄ±sÄ±tlar

* ÃœrÃ¼n: **Validationly** â€” kullanÄ±cÄ± bir fikir/sorgu girer; model, **kendi Ã¶nbilgisi** ve genel pazar sezgileriyle (2025'e kadar tipik teknoloji pazarÄ± normlarÄ±) analiz Ã§Ä±karÄ±r.
* **Veri kÄ±sÄ±tÄ±:** Sadece modelin eÄŸitimiyle sahip olduÄŸu bilgi ve mantÄ±k yÃ¼rÃ¼tme. Harici kaynaklara referans verme; emin olmadÄ±ÄŸÄ±n detaylarda **belirsizlik skoru** ver.
* Hedef ortam: **Vercel + Next.js 14**; bu prompt, `/api/analyze` uÃ§ noktasÄ± iÃ§in **tek adÄ±mda** konsolide bir analiz dÃ¶ndÃ¼rmek Ã¼zere tasarlanmÄ±ÅŸtÄ±r.

---

## 1) Girdi ÅemasÄ±

Model bu prompt ile Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda aÅŸaÄŸÄ±daki \`input\` alanlarÄ±nÄ± bekle:

\`\`\`json
{
  "idea": "kullanÄ±cÄ±nÄ±n fikri veya sorgusu (kÄ±sa paragraf)",
  "audience": "hedef kitle (opsiyonel)",
  "goal": "kullanÄ±cÄ±nÄ±n bu analizden beklediÄŸi amaÃ§ (opsiyonel)",
  "constraints": "ek kÄ±sÄ±tlar (opsiyonel)"
}
\`\`\`

---

## 2) Ã‡Ä±ktÄ± FormatÄ± (Ä°KÄ° PARÃ‡A)

**A) Ä°nsan-okur dostu Markdown Ã¶zet**
**B) Makine tÃ¼ketimi iÃ§in JSON** â€” aÅŸaÄŸÄ±daki ÅŸemaya **harfiyen** uy.

\`\`\`json
{
  "idea_summary": "",
  "assumptions": [{"text":"","confidence":0.0}],
  "target_audience": [""],
  "jobs_to_be_done": [""],
  "value_hypotheses": [""],
  "demand_signals": [{"signal":"","evidence":"model-prior","confidence":0.0}],
  "competitive_landscape": {
    "substitutes": [""],
    "adjacent_tools": [""],
    "moat_likelihood": 0.0
  },
  "risks": [
    {"type":"product","likelihood":0.0,"impact":0.0,"note":""},
    {"type":"market","likelihood":0.0,"impact":0.0,"note":""},
    {"type":"execution","likelihood":0.0,"impact":0.0,"note":""},
    {"type":"legal","likelihood":0.0,"impact":0.0,"note":""}
  ],
  "validation_plan": [
    {"name":"Smoke test landing","cost":"low","metric":"CR >= 5%","success_criteria":">=5% email opt-in"},
    {"name":"Audience interviews (n=10)","cost":"low","metric":"% strong pain","success_criteria":">=70%"},
    {"name":"Concierge prototype","cost":"medium","metric":"paid trials","success_criteria":">=5"}
  ],
  "gtm": {
    "ICP": [""],
    "channels": [""],
    "positioning": "",
    "pricing_hypothesis": {"plan_free":"","plan_pro":"","price_range":""}
  },
  "score_breakdown": {
    "novelty": 0.0,
    "demand_plausibility": 0.0,
    "monetization_clarity": 0.0,
    "feasibility": 0.0,
    "gtm_fit": 0.0
  },
  "final_score": 0,
  "uncertainty_note": "bilinmeyen/veri yok alanlarÄ±nÄ± belirt"
}
\`\`\`

---

## 3) Skorlama RubriÄŸi

* **novelty (0â€“1):** Fikrin bilinen kalÄ±plara gÃ¶re Ã¶zgÃ¼nlÃ¼ÄŸÃ¼.
* **demand_plausibility (0â€“1):** Var sayÄ±lan acÄ±nÄ±n gÃ¼cÃ¼ + Ã¶deme isteÄŸi sezgisi.
* **monetization_clarity (0â€“1):** Gelir modelinin netliÄŸi (abonelik, usage, aracÄ± komisyon vs.).
* **feasibility (0â€“1):** Teknik/operasyonel uygulanabilirlik (MVP karmaÅŸÄ±klÄ±ÄŸÄ±, risk).
* **gtm_fit (0â€“1):** Hedef kanallarla uyum (ICP'ye ulaÅŸÄ±labilirlik).

> **final_score (0â€“100) = 100 * (0.25*demand_plausibility + 0.2*novelty + 0.2*feasibility + 0.2*gtm_fit + 0.15*monetization_clarity)**

---

## 4) DÃ¼ÅŸÃ¼nme Disiplini (Prompt DerinliÄŸi)

AÅŸaÄŸÄ±daki adÄ±mlarÄ± **iÃ§sel olarak** takip et ve sadece sonuÃ§larÄ± Ã§Ä±ktÄ± formatÄ±nda sun:

1. **Decompose:** Fikri parÃ§alara ayÄ±r (mÃ¼ÅŸteri, problem, Ã§Ã¶zÃ¼m, kanal, gelir).
2. **Interrogate:** Her parÃ§a iÃ§in en gÃ¼Ã§lÃ¼ **karÅŸÄ± argÃ¼manÄ±** Ã¼ret.
3. **Synthesize:** En makul varsayÄ±mlarla birleÅŸik model kur.
4. **Score:** RubriÄŸe gÃ¶re puanla; belirsiz alanlara dÃ¼ÅŸÃ¼k gÃ¼ven.
5. **Plan:** 2 hafta iÃ§inde yapÄ±labilecek, **maliyet/dÃ¶nÃ¼ÅŸ** oranÄ± en yÃ¼ksek 3 test.

---

## 5) Ãœslup ve SÄ±nÄ±rlar

* Net, kÄ±sa paragraflar + maddeler. Jargon ÅŸiÅŸirmesi yok.
* **Kesin konuÅŸma**: "muhtemelen", "olasÄ±" gibi kelimeleri sadece belirsizlikte kullan.
* Harici marka/Ã¼rÃ¼n adÄ± verirsen **belirsizlik etiketi** ekle (Ã¶rn. "(dÃ¼ÅŸÃ¼k gÃ¼ven)").
* Asla link verme, kaynak gÃ¶sterme iddiasÄ±nda bulunma.

---

## 6) Uygulama Notu (Vercel/Next.js iÃ§in)

Bu prompt, \`POST /api/analyze\` iÃ§inde **tek Ã§aÄŸrÄ±** ile kullanÄ±lacak. Ã–nerilen inference ayarlarÄ±:

* **temperature: 0.2**, **top_p: 0.9**, **max_tokens: yÃ¼ksek ama pratik (Ã¶rn. 2k)**, **seed** mÃ¼mkÃ¼nse sabitle.
* YanÄ±tÄ± **iki blok** halinde dÃ¶n: Ã¶nce Markdown Ã¶zet, ardÄ±ndan ayrÄ± bir \`\`\`json bloÄŸu.
* Ä°stek baÅŸÄ±na 10s timeout Ã¶ner; daha uzun analiz gerekirse kÄ±sa Ã¶zet + JSON dÃ¶ndÃ¼r.

---

## 7) Ã–rnek Ä°stek (dummy)

\`\`\`json
{
  "idea": "B2B SaaS: X/Twitter, Reddit ve LinkedIn sinyallerinden iÅŸ fikri validasyon skoru Ã¼retir.",
  "audience": "tek kurucular, indie maker'lar, erken aÅŸama ekipler",
  "goal": "yatÄ±rÄ±mcÄ±ya sunum iÃ§in hÄ±zlÄ± analiz",
  "constraints": "harici veri yok, model Ã¶nbilgisi"
}
\`\`\`

**YanÄ±t formatÄ±:** Ã–nce kÄ±sa bir Markdown Ã¶zet (1â€“2 ekran), ardÄ±ndan yukarÄ±daki JSON ÅŸema **eksiksiz** doldurulmuÅŸ olarak.

---

## ANALÄ°Z BAÅLA

**GÄ°RDÄ°:**
Idea: {idea}
Audience: {audience || 'Not specified'}
Goal: {goal || 'Not specified'}
Constraints: {constraints || 'None'}

**LÃ¼tfen yukarÄ±daki formatÄ± takip ederek analiz yapÄ±n. Ã–nce Markdown Ã¶zet, sonra JSON Ã§Ä±ktÄ±sÄ±.**`;

export async function POST(request: Request) {
  try {
    const body: AnalysisInput = await request.json();
    const { idea, audience, goal, constraints } = body;

    if (!idea || !idea.trim()) {
      return Response.json(
        { error: 'Idea is required' },
        { status: 400 }
      );
    }

    console.log('ğŸš€ Starting AI-only analysis for:', idea.substring(0, 100) + '...');

    const ai = getAI();
    let analysisResult: string;

    // AI Analysis based on model type
    if (ai.type === 'openai') {
      const completion = await ai.instance.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: ANALYSIS_PROMPT
          },
          {
            role: 'user',
            content: `Idea: ${idea}\nAudience: ${audience || 'Not specified'}\nGoal: ${goal || 'Not specified'}\nConstraints: ${constraints || 'None'}`
          }
        ],
        temperature: 0.2,
        max_tokens: 4000,
        top_p: 0.9
      });
      analysisResult = completion.choices[0]?.message?.content || '';

    } else if (ai.type === 'groq') {
      const completion = await ai.instance.chat.completions.create({
        model: 'llama3-70b-8192',
        messages: [
          {
            role: 'system',
            content: ANALYSIS_PROMPT
          },
          {
            role: 'user',
            content: `Idea: ${idea}\nAudience: ${audience || 'Not specified'}\nGoal: ${goal || 'Not specified'}\nConstraints: ${constraints || 'None'}`
          }
        ],
        temperature: 0.2,
        max_tokens: 4000,
        top_p: 0.9
      });
      analysisResult = completion.choices[0]?.message?.content || '';

    } else {
      // Gemini
      const model = ai.instance.getGenerativeModel({ model: 'gemini-1.5-pro' });
      const result = await model.generateContent({
        contents: [{
          role: 'user',
          parts: [{
            text: ANALYSIS_PROMPT + `\n\n**GÄ°RDÄ°:**\nIdea: ${idea}\nAudience: ${audience || 'Not specified'}\nGoal: ${goal || 'Not specified'}\nConstraints: ${constraints || 'None'}\n\n**LÃ¼tfen yukarÄ±daki formatÄ± takip ederek analiz yapÄ±n. Ã–nce Markdown Ã¶zet, sonra JSON Ã§Ä±ktÄ±sÄ±.**`
          }]
        }],
        generationConfig: {
          temperature: 0.2,
          topP: 0.9,
          maxOutputTokens: 4000
        }
      });
      analysisResult = result.response.text();
    }

    if (!analysisResult) {
      throw new Error('AI analysis failed - no response generated');
    }

    // Extract JSON from the response
    const jsonMatch = analysisResult.match(/```json\s*([\s\S]*?)\s*```/);
    let parsedResult: AnalysisResult;

    if (jsonMatch && jsonMatch[1]) {
      try {
        parsedResult = JSON.parse(jsonMatch[1]);
      } catch (parseError) {
        console.error('JSON parsing failed:', parseError);
        // Fallback: try to extract JSON from the entire response
        const fallbackMatch = analysisResult.match(/\{[\s\S]*\}/);
        if (fallbackMatch) {
          try {
            parsedResult = JSON.parse(fallbackMatch[0]);
          } catch (fallbackError) {
            throw new Error('Failed to parse AI response as JSON');
          }
        } else {
          throw new Error('No valid JSON found in AI response');
        }
      }
    } else {
      throw new Error('No JSON block found in AI response');
    }

    // Validate required fields
    if (!parsedResult.final_score || !parsedResult.idea_summary) {
      throw new Error('AI response missing required fields');
    }

    console.log('âœ… AI analysis completed successfully');

    return Response.json({
      success: true,
      markdown_summary: analysisResult.replace(/```json[\s\S]*```/, '').trim(),
      analysis: parsedResult,
      ai_model: ai.type,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('âŒ AI analysis failed:', error);
    
    return Response.json(
      { 
        error: 'Analysis failed', 
        details: error instanceof Error ? error.message : 'Unknown error',
        timestamp: new Date().toISOString()
      },
      { status: 500 }
    );
  }
}
